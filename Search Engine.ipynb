{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hollow-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/roy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import porter\n",
    "from nltk.text import TextCollection\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "import re\n",
    "from scipy import spatial\n",
    "from heapq import nlargest\n",
    "import operator\n",
    "import time\n",
    "from data_loader import DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1029cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load():\n",
    "    data = pd.concat([DataLoader(DataLoader.data_path1).load_table(), \\\n",
    "                      DataLoader(DataLoader.data_path2).load_table()], ignore_index = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21d4490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Documents\n",
    "def collect(data):\n",
    "    doc = []\n",
    "    IDdoc = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        # collection of [reviewText] and [summary]\n",
    "        doc.append(preprocess(data.iloc[i]['reviewText'] + ' ' + data.iloc[i]['summary']))\n",
    "        # collection of [reviewerID] and [asin]\n",
    "        IDdoc.append([data.iloc[i]['reviewerID'].lower(), data.iloc[i]['asin'].lower()])\n",
    "        \n",
    "    return doc, IDdoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd7d2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "def preprocess(doc):\n",
    "    # case folding\n",
    "    doc = doc.lower()\n",
    "    \n",
    "    # tokenize \n",
    "    doc = word_tokenize(doc)\n",
    "    \n",
    "    # remove punctuations\n",
    "    doc = [w for w in doc if w.isalnum()]\n",
    "    \n",
    "    # remove stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    doc = [w for w in doc if w not in stop_words]\n",
    "    \n",
    "    # stem\n",
    "    stemmer = porter.PorterStemmer()\n",
    "    doc = [stemmer.stem(w) for w in doc]\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab79fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Index \n",
    "def index(doc, IDdoc):\n",
    "    ind = {}\n",
    "    id_collection = {}\n",
    "    for i in range(len(doc)):\n",
    "        if i%(int(len(doc)/10)) == 0:\n",
    "            start = time.time()\n",
    "        for j in range(len(doc[i])):\n",
    "            if doc[i][j] not in ind.keys():\n",
    "                ind[doc[i][j]] = [1]\n",
    "                ind[doc[i][j]].append({})\n",
    "                ind[doc[i][j]][1][i] = [j]\n",
    "            elif i not in ind[doc[i][j]][1].keys():\n",
    "                ind[doc[i][j]][0] += 1\n",
    "                ind[doc[i][j]][1][i] = [j]\n",
    "            else:\n",
    "                ind[doc[i][j]][1][i].append(j)\n",
    "        if IDdoc[i][0] not in id_collection.keys():\n",
    "            id_collection[IDdoc[i][0]] = [i]\n",
    "        else:\n",
    "            id_collection[IDdoc[i][0]].append(i)\n",
    "        if IDdoc[i][1] not in id_collection.keys():\n",
    "            id_collection[IDdoc[i][1]] = [i]\n",
    "        else: \n",
    "            id_collection[IDdoc[i][1]].append(i)\n",
    "        if (i+1)%(int(len(doc)/10)) == 0:\n",
    "            print(\"%s%% takes %.3f seconds\" % (int((i+1)*10/(int(len(doc)/10))), time.time() - start))\n",
    "    return ind, id_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc81944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(lis, doc, query, index, N):\n",
    "    corpus = []\n",
    "    for i in lis:\n",
    "        corpus.extend(doc[i])\n",
    "    corpus = list(set(corpus))\n",
    "    df = []\n",
    "    for term in corpus:\n",
    "        k = 0\n",
    "        for i in lis:\n",
    "            if i in index[term][1]:\n",
    "                k+=1\n",
    "        df.append(k)\n",
    "    \n",
    "    tfidf = np.empty([len(lis), len(corpus)])\n",
    "    for i in range(len(lis)):\n",
    "        sumsquare = 0 \n",
    "        for j, term in enumerate(corpus):\n",
    "            if doc[lis[i]].count(term) == 0:\n",
    "                tfidf[i][j] = 0\n",
    "            else:\n",
    "                tfidf[i][j] = (1 + math.log10(doc[lis[i]].count(term)))\n",
    "            sumsquare += tfidf[i][j] * tfidf[i][j]\n",
    "        norm = math.sqrt(sumsquare)\n",
    "        tfidf[i] /= norm\n",
    "        \n",
    "    qvector = np.empty(len(corpus))\n",
    "    sumsquare = 0\n",
    "    for i, term in enumerate(corpus):\n",
    "        if query.count(term) == 0:\n",
    "            qvector[i] = 0\n",
    "        elif df[i] == len(lis):\n",
    "            qvector[i] = (1 + math.log10(query.count(term)))\n",
    "        else:\n",
    "            qvector[i] = (1 + math.log10(query.count(term))) * math.log10(len(lis)/df[i])\n",
    "        sumsquare += qvector[i] * qvector[i]\n",
    "    norm = math.sqrt(sumsquare)\n",
    "    if norm != 0:\n",
    "        qvector /= norm\n",
    "    result = []\n",
    "    cs = np.matmul(tfidf,qvector)\n",
    "    index = nlargest(min(len(lis), N), enumerate(cs), key=operator.itemgetter(1))\n",
    "    for i in range(min(len(lis), N)):\n",
    "                result.append(lis[index[i][0]])\n",
    "    score = nlargest(min(len(lis), N),cs)\n",
    "    return result, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3785deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(lis, query):\n",
    "    k = 0\n",
    "    while len(lis) > 0:\n",
    "        newlis = {}\n",
    "        for i in range(len(query)-1):\n",
    "            if query[i] not in lis.keys():\n",
    "                continue\n",
    "            if query[i+1] not in lis.keys():\n",
    "                continue\n",
    "            for pos in lis[query[i]]:\n",
    "                if pos+1 in lis[query[i+1]]:\n",
    "                    if query[i+1] not in newlis.keys():\n",
    "                        newlis[query[i+1]] = [pos]\n",
    "                    else:\n",
    "                        newlis[query[i+1]].append(pos)\n",
    "        lis = newlis  \n",
    "        k += 1\n",
    "    return k                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "smooth-better",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roy/Desktop/Python/6122 A1 Review Data Analysis and Processing/data_loader.py:14: FutureWarning: Starting with pandas version 2.0 all arguments of read_json except for the argument 'path_or_buf' will be keyword-only.\n",
      "  self.table = pd.read_json(data_path, 'records', lines = True);\n",
      "/Users/roy/Desktop/Python/6122 A1 Review Data Analysis and Processing/data_loader.py:14: FutureWarning: Starting with pandas version 2.0 all arguments of read_json except for the argument 'path_or_buf' will be keyword-only.\n",
      "  self.table = pd.read_json(data_path, 'records', lines = True);\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "data = load()\n",
    "# Collect Documents & Preprocess\n",
    "doc, IDdoc = collect(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe7a862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% takes 0.111 seconds\n",
      "20% takes 0.033 seconds\n",
      "30% takes 0.099 seconds\n",
      "40% takes 0.125 seconds\n",
      "50% takes 0.058 seconds\n",
      "60% takes 0.187 seconds\n",
      "70% takes 0.201 seconds\n",
      "80% takes 0.215 seconds\n",
      "90% takes 0.108 seconds\n",
      "100% takes 0.242 seconds\n"
     ]
    }
   ],
   "source": [
    "# Positional Index    \n",
    "ind, id_collection = index(doc, IDdoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "953eb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(index, id_collection, query, docum, data, N=10):\n",
    "    resultIndex = []\n",
    "    resultScore = []\n",
    "    doubleid = []\n",
    "    singleid = []\n",
    "    \n",
    "    for term in query:\n",
    "        if term in id_collection.keys():\n",
    "            for doc in id_collection[term]:\n",
    "                if doc not in singleid:\n",
    "                    singleid.append(doc)\n",
    "                else:\n",
    "                    singleid.remove(doc)\n",
    "                    doubleid.append(doc)\n",
    "                    \n",
    "    allId = {}\n",
    "    k = 0\n",
    "    for term in query:\n",
    "        if term in index.keys():\n",
    "            k+=1\n",
    "            for doc, pos in index[term][1].items():\n",
    "                if doc not in allId.keys():\n",
    "                    allId[doc] = [1, 0]\n",
    "                    allId[doc].append({})\n",
    "                else:\n",
    "                    allId[doc][0] += 1\n",
    "                if term not in allId[doc][2].keys():\n",
    "                    allId[doc][2][term] = pos\n",
    "                \n",
    "    for i in range(k):\n",
    "        if len(dict(filter(lambda elem: elem[1][0] >= k-i, allId.items()))) >= 50:\n",
    "            allId = dict(filter(lambda elem: elem[1][0] >= k-i or elem[0] in singleid or elem[0] in doubleid, allId.items()))\n",
    "            break\n",
    "    \n",
    "    i = 2\n",
    "    while len(allId) > 200:\n",
    "        allId = dict(filter(lambda elem: len(list(elem[1][2].values())[0]) >= i or elem[0] in singleid or elem[0] in doubleid, allId.items()))\n",
    "        i+=1\n",
    "                    \n",
    "    for i in range(k):\n",
    "        kIndex = []\n",
    "        for doc, value in allId.items():\n",
    "            if doc in doubleid:\n",
    "                if value[0] >= k-i:\n",
    "                    if value[1] == 0:\n",
    "                        value[1] = check(value[2], query)\n",
    "                    if value[1] == k-i:\n",
    "                        kIndex.append(doc)\n",
    "        kIndex, score = rank(kIndex, docum, query, index, N-len(resultIndex))\n",
    "        for j in range(len(score)):\n",
    "            score[j] += (k-i)\n",
    "        resultIndex.extend(kIndex)\n",
    "        resultScore.extend(score)\n",
    "        if len(resultIndex) >= N:\n",
    "            resultSnippet = snippet(resultIndex, query, allId, data)\n",
    "            return resultIndex, resultScore, resultSnippet\n",
    "    for doc in doubleid:\n",
    "        if doc not in resultIndex:\n",
    "            resultIndex.append(doc)\n",
    "            resultScore.append(0)\n",
    "            if len(resultIndex) >= N:\n",
    "                resultSnippet = snippet(resultIndex, query, allId, data)\n",
    "                return resultIndex, resultScore, resultSnippet\n",
    "    for i in range(len(resultScore)):\n",
    "        resultScore[i] += (1+k)\n",
    "    \n",
    "    for i in range(k):\n",
    "        kIndex = []\n",
    "        for doc, value in allId.items():\n",
    "            if doc in singleid:\n",
    "                if value[0] >= k-i:\n",
    "                    if value[1] == 0:\n",
    "                        value[1] = check(value[2], query)\n",
    "                    if value[1] == k-i:\n",
    "                        kIndex.append(doc)\n",
    "        kIndex, score = rank(kIndex, docum, query, index, N-len(resultIndex))\n",
    "        for j in range(len(score)):\n",
    "            score[j] += (k-i)\n",
    "        resultIndex.extend(kIndex)\n",
    "        resultScore.extend(score)\n",
    "        if len(resultIndex) >= N:\n",
    "            resultSnippet = snippet(resultIndex, query, allId, data)\n",
    "            return resultIndex, resultScore, resultSnippet\n",
    "    for doc in singleid:\n",
    "        if doc not in resultIndex:\n",
    "            resultIndex.append(doc)\n",
    "            resultScore.append(0)\n",
    "            if len(resultIndex) >= N:\n",
    "                resultSnippet = snippet(resultIndex, query, allId, data)\n",
    "                return resultIndex, resultScore, resultSnippet\n",
    "    for i in range(len(resultScore)):\n",
    "        resultScore[i] += (1+k)\n",
    "    \n",
    "    for i in range(k):\n",
    "        kIndex = []\n",
    "        for doc, value in allId.items():\n",
    "            if doc not in singleid and doc not in doubleid:\n",
    "                if value[0] >= k-i:\n",
    "                    if value[1] == 0:\n",
    "                        value[1] = check(value[2], query)\n",
    "                    if value[1] == k-i:\n",
    "                        kIndex.append(doc)\n",
    "        kIndex, score = rank(kIndex, docum, query, index, N-len(resultIndex))\n",
    "        for j in range(len(score)):\n",
    "            score[j] += (k-i)\n",
    "        resultIndex.extend(kIndex)\n",
    "        resultScore.extend(score)\n",
    "        if len(resultIndex) >= N:\n",
    "            resultSnippet = snippet(resultIndex, query, allId, data)\n",
    "            return resultIndex, resultScore, resultSnippet\n",
    "    \n",
    "    resultSnippet = snippet(resultIndex, query, allId, data)\n",
    "    return resultIndex, resultScore, resultSnippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "415fc65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snippet(resultIndex, query, allId, data):\n",
    "    snippets = []\n",
    "    for doc in resultIndex:\n",
    "        if doc not in allId:\n",
    "            snippets.append(\"\")\n",
    "        else:\n",
    "            allindex = {}\n",
    "            k=0\n",
    "            while len(allId[doc][2]) > 0:\n",
    "                newlis = {}\n",
    "                newterm = []\n",
    "                for i in range(len(query)-1):\n",
    "                    if query[i] not in allId[doc][2].keys():\n",
    "                        continue\n",
    "                    if query[i+1] not in allId[doc][2].keys():\n",
    "                        continue\n",
    "                    for pos in allId[doc][2][query[i]]:\n",
    "                        if pos+1 in allId[doc][2][query[i+1]]:\n",
    "                            if query[i+1] not in newlis.keys():\n",
    "                                newlis[query[i+1]] = [pos]\n",
    "                            else:\n",
    "                                newlis[query[i+1]].append(pos)\n",
    "                            for term in query[i:i+k+2]:\n",
    "                                if term not in newterm:\n",
    "                                    newterm.append(query[i])\n",
    "                if len(allId[doc][2]) != len(newterm):\n",
    "                    for term in allId[doc][2].keys():\n",
    "                        if term not in newterm:\n",
    "                            allindex[allId[doc][2][term][0]] = k        \n",
    "                allId[doc][2] = newlis  \n",
    "                k += 1\n",
    "            \n",
    "            text = []\n",
    "            for term in (data.iloc[doc]['reviewText'] + ' ' + data.iloc[doc]['summary']).split():\n",
    "                if preprocess(term) == []:\n",
    "                    text.append(\"\")\n",
    "                else:\n",
    "                    text.append(preprocess(term)[0])\n",
    "            \n",
    "            realindex = {}\n",
    "            curr = -1\n",
    "            prev = -1\n",
    "            k = 0\n",
    "            \n",
    "            for i, term in enumerate(text):\n",
    "                if k == 0:\n",
    "                    if prev in realindex.keys():\n",
    "                        realindex[prev] = i\n",
    "                        prev = -1\n",
    "                    if term != \"\":\n",
    "                        curr += 1\n",
    "                    if curr in allindex.keys():\n",
    "                        realindex[i] = i+1\n",
    "                        k = allindex[curr]\n",
    "                        prev = i\n",
    "                else:\n",
    "                    if term != \"\":\n",
    "                        curr += 1\n",
    "                        k-=1\n",
    "            \n",
    "            wholeindex =[]\n",
    "            for start in sorted(realindex.keys()):\n",
    "                printstart = start-3\n",
    "                printend = realindex[start]+3\n",
    "                if printstart < 0:\n",
    "                    printstart = 0\n",
    "                if printend > len(text)-1:\n",
    "                    printend = len(text)-1\n",
    "                wholeindex.append([printstart, printend])\n",
    "            \n",
    "            if len(wholeindex) == 0:\n",
    "                snippet = []\n",
    "                snippet.append(\"...\")\n",
    "                for i in range(10):\n",
    "                    snippet.append((data.iloc[doc]['reviewText'] + ' ' + data.iloc[doc]['summary']).split()[-10+i])\n",
    "                snippets.append(\" \".join(snippet))\n",
    "                continue\n",
    "                \n",
    "            result = []\n",
    "            for i in range(wholeindex[-1][1]+1):\n",
    "                for index in wholeindex:\n",
    "                    if i >= index[0] and i <= index[1]:\n",
    "                        result.append(i)\n",
    "                        break\n",
    "            \n",
    "            snippet = []\n",
    "            if result[0] != 0:\n",
    "                snippet.append(\"...\")\n",
    "            for i in range(result[0], result[-1]+1):\n",
    "                if i in result:\n",
    "                    snippet.append((data.iloc[doc]['reviewText'] + ' ' + data.iloc[doc]['summary']).split()[i])\n",
    "                elif snippet[-1] != \"...\":\n",
    "                    snippet.append(\"...\")\n",
    "            if result[-1] != len(text)-1:\n",
    "                snippet.append(\"...\")\n",
    "            snippets.append(\" \".join(snippet))\n",
    "    return snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54024f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for: (type \"q\" to quit) ed\n",
      "   Rank  DocID      ReviewerID        asin  \\\n",
      "0     1   2703  A2N82JI7471GAC  B007NUVFN6   \n",
      "1     2   4435  A1F7WZJ2VJAHMV  B00AUHWRVI   \n",
      "2     3   3000  A2RAO7KNA08S85  B007PPJOGO   \n",
      "3     4  11057  A264CMSE6CYHTF  B000002PHV   \n",
      "4     5  10930  A264CMSE6CYHTF  B000002NAA   \n",
      "5     6   9396  A264CMSE6CYHTF  B0000025RI   \n",
      "6     7   6168  A3T8O3MMI1J1JG  B00E8HWZ36   \n",
      "7     8   6146  A3PXSUV3A8090B  B00E8HWZ36   \n",
      "8     9  11999  A1G5LJ8T1IGYC5  B00000FCBH   \n",
      "9    10  13127   A8TM0MI3D9T29  B00006M183   \n",
      "\n",
      "                                            Snippets     Score  \n",
      "0            It peek ed my interest. A nice fast ...  1.274625  \n",
      "1      ... ain't everything to ed everybody... Cesar  1.250000  \n",
      "2         ... I really enjoy ed this book Great read  1.205106  \n",
      "3     ... school. ed wilson every little step i take  1.194391  \n",
      "4   ... a lot. ed wilson good collcetion of classics  1.160601  \n",
      "5          ... but then again,that's another review.  1.142580  \n",
      "6  ... about Kendall and Ed. Kendall has her sigh...  1.137864  \n",
      "7   ... brothers best friend Ed. Ed has been put ...  1.115676  \n",
      "8   ... THIS IS THE COLLECTION I'VE WAITED YEARS FOR  1.112864  \n",
      "9     ... memory. The way Ed sings the verses is ...  1.112501  \n",
      "Search takes 0.512 seconds\n",
      "Search for: (type \"q\" to quit) say\n",
      "   Rank  DocID      ReviewerID        asin  \\\n",
      "0     1  13069   A9GYC5DZSSSLT  B00006JO3X   \n",
      "1     2  13681   AQDRA2PILMEAY  B00009VRDI   \n",
      "2     3  11937   AJJYB8VYH43PB  B00000FCBH   \n",
      "3     4  13467  A3EAU736LWTDCE  B00008J4P5   \n",
      "4     5  10361  A26NLSTT75FMJM  B000002HQD   \n",
      "5     6  11466   AEJMORY9FL6PI  B000003AEK   \n",
      "6     7  10122   ADTUS88NFTW23  B000002AP1   \n",
      "7     8  11298  A16YQ1TL4J62L0  B0000039Q3   \n",
      "8     9  14373  A34Y1FT0MTD7C9  B00028HOFY   \n",
      "9    10  11942  A3S34VW0BBC9L6  B00000FCBH   \n",
      "\n",
      "                                            Snippets     Score  \n",
      "0  ... do is say yes......The title says it all.I...  1.317622  \n",
      "1  ... AHHH,U SAY I SAY ,I DON'T MIND AND THE HOT...  1.224347  \n",
      "2  ... r stupid for saying that because all rap f...  1.204496  \n",
      "3  ... they are &quot;musically strong&quot; You ...  1.183654  \n",
      "4  ... much I can say to do the song justice. Nee...  1.173103  \n",
      "5  ... What's there to say? He was amazing. There...  1.172597  \n",
      "6  ... the guts to say it. If you don't like The ...  1.170787  \n",
      "7  ... what can i say, this is just an excellent ...  1.170548  \n",
      "8  ... Now I'm not saying that is bad, because I ...  1.164540  \n",
      "9  ... feet. It's not saying that Chingy has no t...  1.161497  \n",
      "Search takes 1.262 seconds\n",
      "Search for: (type \"q\" to quit) ed sheeran\n",
      "   Rank  DocID      ReviewerID        asin  \\\n",
      "0     1   7928   AHXJNXJSX2NFV  B00II4IHQ4   \n",
      "1     2   2703  A2N82JI7471GAC  B007NUVFN6   \n",
      "2     3   4435  A1F7WZJ2VJAHMV  B00AUHWRVI   \n",
      "3     4   3000  A2RAO7KNA08S85  B007PPJOGO   \n",
      "4     5  11057  A264CMSE6CYHTF  B000002PHV   \n",
      "5     6  10930  A264CMSE6CYHTF  B000002NAA   \n",
      "6     7   9396  A264CMSE6CYHTF  B0000025RI   \n",
      "7     8   6168  A3T8O3MMI1J1JG  B00E8HWZ36   \n",
      "8     9   6146  A3PXSUV3A8090B  B00E8HWZ36   \n",
      "9    10  11999  A1G5LJ8T1IGYC5  B00000FCBH   \n",
      "\n",
      "                                            Snippets     Score  \n",
      "0  ... Big World feat. Christina Aguilera&#10084;...  2.081199  \n",
      "1            It peek ed my interest. A nice fast ...  1.274625  \n",
      "2      ... ain't everything to ed everybody... Cesar  1.250000  \n",
      "3         ... I really enjoy ed this book Great read  1.205106  \n",
      "4     ... school. ed wilson every little step i take  1.194391  \n",
      "5   ... a lot. ed wilson good collcetion of classics  1.160601  \n",
      "6          ... but then again,that's another review.  1.142580  \n",
      "7  ... about Kendall and Ed. Kendall has her sigh...  1.137864  \n",
      "8   ... brothers best friend Ed. Ed has been put ...  1.115676  \n",
      "9   ... THIS IS THE COLLECTION I'VE WAITED YEARS FOR  1.112864  \n",
      "Search takes 0.549 seconds\n",
      "Search for: (type \"q\" to quit) talyor\n",
      "Empty DataFrame\n",
      "Columns: [Rank, DocID, ReviewerID, asin, Snippets, Score]\n",
      "Index: []\n",
      "Search takes 0.003 seconds\n",
      "Search for: (type \"q\" to quit) kanye\n",
      "   Rank  DocID      ReviewerID        asin  \\\n",
      "0     1  14491  A151JSJYHTN4T2  B0002TL6QQ   \n",
      "1     2  14864  A3LZJBC7TTXWJ3  B0006ZQ9BS   \n",
      "2     3  14986  A1XHEPURAYWC6A  B0006ZQ9BS   \n",
      "3     4  14483  A2WRWK0ARXOFSZ  B0002TL6QQ   \n",
      "4     5  13027  A2CA36LT9SXGNI  B00006C2H3   \n",
      "5     6  14477  A2UXKWVHJ0JSHN  B0002TL6QQ   \n",
      "6     7  14281  A19HIVCY0C6DQ3  B0001BXYRO   \n",
      "7     8  14974  A34N9A38XTNOB9  B0006ZQ9BS   \n",
      "8     9  14475   AYZXJ9FOTOSY4  B0002TL6QQ   \n",
      "9    10  14892   AYZXJ9FOTOSY4  B0006ZQ9BS   \n",
      "\n",
      "                                            Snippets     Score  \n",
      "0  ... by Kanyeezee aka Kanye West. I've always b...  1.242536  \n",
      "1  ... cd, because behind Kanye's cd, this is the...  1.211585  \n",
      "2  ... Mainstream Rap album since Kanye West's Co...  1.206335  \n",
      "3  ... the industry. Yeah Kanye may have laced th...  1.190425  \n",
      "4  ... good production from Kanye West with good ...  1.168386  \n",
      "5  ... Forever produce by KANYE WEST. O that I'm ...  1.157206  \n",
      "6  ... the Alchemist and Kanye West in their arti...  1.149987  \n",
      "7  ... while. Even the Kanye track, Dream, is ama...  1.149488  \n",
      "8  ... Includes appearances by Kanye West, the Di...  1.147317  \n",
      "9  ... Tony Yayo, and production by Kanye West, T...  1.144410  \n",
      "Search takes 1.021 seconds\n",
      "Search for: (type \"q\" to quit) Justin biber\n",
      "   Rank  DocID      ReviewerID        asin  \\\n",
      "0     1  16314  A14YZ43JUA3ULY  B00B165ELW   \n",
      "1     2   5891  A28MPK002D2WJ1  B00DK6MXCY   \n",
      "2     3  16322  A1B1B68XXFLUGC  B00B165ELW   \n",
      "3     4   5895  A2XMUC9USK6QVO  B00DK6MXCY   \n",
      "4     5  16317  A35CHV6Z75D672  B00B165ELW   \n",
      "5     6  16329  A2GN4BPR465KFS  B00B165ELW   \n",
      "6     7   5898  A380C702FXX01N  B00DK6MXCY   \n",
      "7     8   1988  A2103X7H4V415L  B006PVGZ0W   \n",
      "8     9  16321   ADN5YE0HOKE6O  B00B165ELW   \n",
      "9    10   9468  A2OBBLBDCXSBQ4  B0000025RI   \n",
      "\n",
      "                                            Snippets     Score  \n",
      "0  ... the radio and Justin and Jay-Z is two arti...  1.310305  \n",
      "1  ... first one was- Justine, we're late). It's ...  1.279777  \n",
      "2                     justin's back great song & ...  1.278698  \n",
      "3  ... this series called: Justine, we're late, a...  1.276890  \n",
      "4  ... it. Good job Justin Timberlake and Jay-Z, ...  1.263657  \n",
      "5  ... to do with Justin but Justin really vocall...  1.234541  \n",
      "6  ... book: Justine, we're late! (Conflict resol...  1.216060  \n",
      "7  ... and smart, and Justin is the perfect littl...  1.215329  \n",
      "8  ... songs such as Sexyback and Rock your body....  1.214757  \n",
      "9  ... Infedil, he's copying Justin timberlake? h...  1.193609  \n",
      "Search takes 0.492 seconds\n",
      "Search for: (type \"q\" to quit) maroon 5\n",
      "   Rank  DocID      ReviewerID        asin  \\\n",
      "0     1  11322  A1F0K9QTWPSX7Z  B0000039Q3   \n",
      "1     2   4445   A3J89EOHRG4HZ  B00AUK88RW   \n",
      "2     3   4474  A3TGSJ1C70E08Q  B00AXTM8G2   \n",
      "3     4   1343  A3DIHSUH21GS86  B005FR8OTM   \n",
      "4     5   7241  A2AXBR2JA2VKRQ  B00GQHCBI0   \n",
      "5     6  14639  A1SPYMGDEWKK6I  B00065JTAQ   \n",
      "6     7   5537   AMCZHLD6Y3F5S  B00CEL5530   \n",
      "7     8  15149  A12A6ZP3S3W2P6  B0009VJWQS   \n",
      "8     9  13703  A32207GKRIJYDI  B0000A5A0K   \n",
      "9    10   9396  A264CMSE6CYHTF  B0000025RI   \n",
      "\n",
      "                                            Snippets     Score  \n",
      "0                               5 Mics 5 stars 5 ...  1.441732  \n",
      "1  ... cookbook calls for 5 ingredients, I have f...  1.355609  \n",
      "2  ... 4 out of 5 starsfree ebook Basic numerical...  1.346750  \n",
      "3                          5 StarsI do not write ...  1.321410  \n",
      "4                  5 Stars!Love this super sweet ...  1.321410  \n",
      "5           ... 5 out of 5 Ludacris is very best ...  1.305335  \n",
      "6                 First 5 books are really great ...  1.288156  \n",
      "7     ... definitely a top 5 Cd of the year.Teds ...  1.272312  \n",
      "8         ... this CD a 5 star rating. But, that ...  1.248929  \n",
      "9  ... top an album like this? the answer is you ...  1.210607  \n",
      "Search takes 1.683 seconds\n",
      "Search for: (type \"q\" to quit) one republic\n",
      "   Rank  DocID      ReviewerID        asin  \\\n",
      "0     1   9433  A3QZA3MXC75V4E  B0000025RI   \n",
      "1     2  15455  A2AOZQ3WTNVVOK  B000EHQ80A   \n",
      "2     3   9588  A3SR070FB0C7HU  B00000269M   \n",
      "3     4   9295   AQFE4WTGEQI0M  B0000025F7   \n",
      "4     5   6731  A34CMWVCTW1IZH  B00FI5RKMI   \n",
      "5     6  11276  A18DP77H7EOJ1U  B0000039Q3   \n",
      "6     7   7154  A3N4FI8YRIUJLB  B00GGKHFW4   \n",
      "7     8  12996  A2NLP8TW1TCKN3  B00005U2LE   \n",
      "8     9  12131  A2JEWRZ7E7RE2V  B00000JC6C   \n",
      "9    10   9344  A35L2E8M7S59MQ  B0000025F7   \n",
      "\n",
      "                                            Snippets     Score  \n",
      "0  This is definitely one of Michael Jackson's de...  1.221829  \n",
      "1  ... particular collection is one of the better...  1.188571  \n",
      "2  ... of my prized albums. The music was so raw ...  1.180896  \n",
      "3  ... Jackson's best album. One of the few album...  1.177489  \n",
      "4     ... read this in one sitting. Not one day. ...  1.174315  \n",
      "5       Biggie, one of the greatest MC's to ever ...  1.167533  \n",
      "6   ... unique and tragic one. One that you will ...  1.166191  \n",
      "7  Someone say this one is bad,Have mtv feel, too...  1.164453  \n",
      "8  ... immediately enjoy, but one that is not so ...  1.163559  \n",
      "9  ... The Wall is one of the best albums ever re...  1.163541  \n",
      "Search takes 3.689 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for: (type \"q\" to quit) onerepublic\n",
      "Empty DataFrame\n",
      "Columns: [Rank, DocID, ReviewerID, asin, Snippets, Score]\n",
      "Index: []\n",
      "Search takes 0.002 seconds\n",
      "Search for: (type \"q\" to quit) hallwood\n",
      "Empty DataFrame\n",
      "Columns: [Rank, DocID, ReviewerID, asin, Snippets, Score]\n",
      "Index: []\n",
      "Search takes 0.002 seconds\n",
      "Search for: (type \"q\" to quit) goodnight\n",
      "   Rank  DocID      ReviewerID        asin  \\\n",
      "0     1  15256  A1YTLL3606WSQZ  B000AL730O   \n",
      "1     2  15188  A1GN8UJIZLCA59  B0009YA3CC   \n",
      "2     3  15184  A3AP4XR4NYHQTJ  B0009YA3CC   \n",
      "3     4  15169  A1AYEI2SNFPYES  B0009YA3CC   \n",
      "4     5  15183  A2Q4WJ3NPIVA8E  B0009YA3CC   \n",
      "5     6  15161   A918P6KPDBN0Q  B0009YA3CC   \n",
      "6     7  12829   ABOSS65WG9EZV  B00005QK3W   \n",
      "7     8  15168   A2EUG9W2IAVCT  B0009YA3CC   \n",
      "8     9  15189  A31RP6XY9IESQ5  B0009YA3CC   \n",
      "9    10  15181  A3AL8GQ69QE7WN  B0009YA3CC   \n",
      "\n",
      "                                            Snippets     Score  \n",
      "0  ... \"Let Em In,\" \"Goodnight Tonight,\" \"Say Say...  1.152177  \n",
      "1  ... pulsating bass lines. \"Goodnight & Go\" is ...  1.145939  \n",
      "2  ... on the road. Goodnight and Go is cute fun,...  1.134370  \n",
      "3  ... On the bittersweet Goodnight and Go (also ...  1.132297  \n",
      "4  ... (my personal favorite), \"Goodnight and Go,...  1.125946  \n",
      "5  ... tracks with \"Headlock\", \"Goodnight and Go\"...  1.110168  \n",
      "6  ... and was &quot;Goodnight Tonight&quot;, by ...  1.104569  \n",
      "7  ... enjoyable; \"Goodnight and Go\" and the afor...  1.099029  \n",
      "8  ... right. \"Headlock\" and \"Goodnight and Go\" s...  1.098978  \n",
      "9  ... single \"Goodnight And Go\", \"Headlock\", \"Lo...  1.087429  \n",
      "Search takes 0.265 seconds\n",
      "Search for: (type \"q\" to quit) birthdays\n",
      "   Rank  DocID      ReviewerID        asin  \\\n",
      "0     1   9675   A6ATIU768OFXM  B0000026WD   \n",
      "1     2   9138  A2JGCIS4LEPFC2  B000001FFJ   \n",
      "2     3   6862  A1X2O9QW52WYJU  B00FL3VPD2   \n",
      "3     4   2596  A3C83JYGV84IXJ  B007D788ZW   \n",
      "4     5  15048  A2T1XP65APNTK1  B0007WF1XC   \n",
      "5     6  10544   API8LHQI6HWKX  B000002KHB   \n",
      "6     7  15615  A3VXBO4QQX3ZG8  B000MTPAGI   \n",
      "7     8  11675   A2C5MM01EHB2F  B0000062QH   \n",
      "8     9  10122   ADTUS88NFTW23  B000002AP1   \n",
      "9    10    752   A7NDR999YTJ7N  B004KSQVBA   \n",
      "\n",
      "                                            Snippets     Score  \n",
      "0  ... sister for her birthday, she really loves ...  1.316228  \n",
      "1  ... on my 21st birthday. It didn't leave my ca...  1.141311  \n",
      "2  ... me for my birthday many times over!So buy ...  1.123363  \n",
      "3  ... for the birthday party. What??? Ok the who...  1.117010  \n",
      "4        ... album as a birthday gift, I can now ...  1.116483  \n",
      "5  ... my most recent birthday my rock buddy boug...  1.108643  \n",
      "6  ... birthday, so, Happy Birthday, Joss! Joss S...  1.106723  \n",
      "7  ... play at your birthday party.1-Star: If you...  1.106643  \n",
      "8  ... no Ramones, no Birthday Party, no Black Fl...  1.106604  \n",
      "9  ... on his 100th birthday. In this first book,...  1.094837  \n",
      "Search takes 0.379 seconds\n",
      "Search for: (type \"q\" to quit) fff\n",
      "Empty DataFrame\n",
      "Columns: [Rank, DocID, ReviewerID, asin, Snippets, Score]\n",
      "Index: []\n",
      "Search takes 0.002 seconds\n",
      "Search for: (type \"q\" to quit) c\n",
      "   Rank  DocID      ReviewerID        asin  \\\n",
      "0     1   2879  A32PYP772QZE4T  B007PCRT0U   \n",
      "1     2  10357  A1P6NTDL1BKLDV  B000002H8I   \n",
      "2     3   1801   APXDIBUU4CXTU  B0068XJXJC   \n",
      "3     4  13608  A3OLZXHFGUAMWW  B00009MGQH   \n",
      "4     5   4433  A3Q781G7YB6KK5  B00AUHWRVI   \n",
      "5     6   9946   AGZ28CC1MLUAD  B00000294R   \n",
      "6     7   8583  A19Y9WYDSVWRU9  B00LK1BKBQ   \n",
      "7     8   3117   AU8EUV2451CLO  B007U0ZP76   \n",
      "8     9  13602   A31U2QT7SAL7K  B00009MGQH   \n",
      "9    10   2295  A1I1GD8RH5T7XK  B007418CL2   \n",
      "\n",
      "                                            Snippets     Score  \n",
      "0  ... C uncritically. Why waste your time? Same ...  1.247043  \n",
      "1   ... what happened but C Brown was a star.Top ...  1.229076  \n",
      "2  ... Dan (Parkside Community C....by Katie Crab...  1.217814  \n",
      "3        ... is washed up, c ya mariah been nice ...  1.204329  \n",
      "4  ... out on top!! C&auml;sar with all the lows ...  1.199276  \n",
      "5   ... REMIND ME OF C...U...m!!!!! BIG L IS AND ...  1.190191  \n",
      "6                       ... (Chi Running, Running, C  1.187791  \n",
      "7       ... any of T C Barnes' books but believe ...  1.176063  \n",
      "8  ... David Morales and C & C Music Factory, are...  1.169319  \n",
      "9  ... me of Arthur C Clarke's Venus Prime books ...  1.165655  \n",
      "Search takes 0.439 seconds\n",
      "Search for: (type \"q\" to quit) happen\n",
      "   Rank  DocID      ReviewerID        asin  \\\n",
      "0     1   3112  A1S0QQ9Q5FRI1B  B007U0ZP76   \n",
      "1     2   3952   AKQ30BBS21S7N  B008WW3WBM   \n",
      "2     3   2581  A1RVTF261ZMY4M  B007D788ZW   \n",
      "3     4   1545  A2EUHURZMCMHQ5  B0061YAUG8   \n",
      "4     5   4588  A2B2KVPU0E7X19  B00AXTM8G2   \n",
      "5     6   4965   A44QEXW6NO4JJ  B00BD63EIK   \n",
      "6     7   6389  A1A4B1EWE6HDAF  B00EEPZ5HA   \n",
      "7     8   7747  A3U5XGP2R8CLAE  B00HV5YH24   \n",
      "8     9   6513   AI0KSISN9CC6Y  B00EN0ZKIK   \n",
      "9    10   4629  A3KBRXW4PKK2MT  B00AXTM8G2   \n",
      "\n",
      "                                            Snippets     Score  \n",
      "0   ... what's going to happen next and what was ...  1.385580  \n",
      "1  ... that told what happened afterward, so I th...  1.331691  \n",
      "2  ... could imagine it happening. The characters...  1.321410  \n",
      "3  ... was going to happen with Lou and Sam. Kept...  1.308628  \n",
      "4  ... Noah and relationship happens. Just when i...  1.293180  \n",
      "5  ... a follow up.Whatever happens to the days w...  1.269039  \n",
      "6  ... sure what just happened. Micah gives off t...  1.261407  \n",
      "7  ... was gonna happen next. The plot was thick ...  1.247232  \n",
      "8   ... to see what happens next. Can't wait for ...  1.245286  \n",
      "9  ... one, maybe it happens in a one night stand...  1.243862  \n",
      "Search takes 1.860 seconds\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Query\n",
    "    query = input(\"Search for: (type \\\"q\\\" to quit) \")\n",
    "    if query == \"q\":\n",
    "        break\n",
    "    start = time.time()\n",
    "    # Prepocess Query\n",
    "    query = preprocess(query)\n",
    "    # Result\n",
    "    keyList = [\"Rank\", \"DocID\", \"ReviewerID\", \"asin\", \"Snippets\", \"Score\"]\n",
    "    results = {key: [] for key in keyList}\n",
    "    docIDs, scores, snippets = result(ind, id_collection, query, doc, data)\n",
    "\n",
    "    for i, docID in enumerate(docIDs):\n",
    "        results[\"Rank\"].append(i+1)\n",
    "        results[\"DocID\"].append(docID)\n",
    "        results[\"ReviewerID\"].append(data.loc[docID][\"reviewerID\"])\n",
    "        results[\"asin\"].append(data.loc[docID][\"asin\"])\n",
    "        results[\"Snippets\"].append(snippets[i])\n",
    "        results[\"Score\"].append(scores[i])\n",
    "    print(pd.DataFrame(results))\n",
    "    print(\"Search takes %.3f seconds\" % (time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
